[
  {
    "link": "https://uxplanet.org/the-details-that-matter-8b962ca58b49?source=---------0-----------",
    "pic": "https://cdn-images-1.medium.com/fit/c/36/36/1*ftnOlIAh5nolCvvrhc44-Q.png",
    "author": "",
    "date": "Mar 23",
    "photo": "https://cdn-images-1.medium.com/max/800/1*xv6xhcRljayCKY15LDekfQ.png",
    "head": "The Details That Matter",
    "contents": "Your product’s success is based on a combination of factors, but the overall user experience tops them all. When it comes down to designing a new app or a site, sticking to best practices is a solid way to go, but during the creation of the big picture, it’s fairly easy to skimp over design elements that feel like nice to have but not necessary. However, the difference between good and bad experiences often comes down to how thoughtful we can design these small details.In this article, I’ll focus on visual feedback, microcopy and whitespace and you’ll see why these little big details are just as important as the more obvious elements of your design, and how they help determine the success of your product.Visual feedback might be easily overlooked in the greater design scheme, but it actually hold the entire experience together. When there’s no feedback there’s no proper interaction. Imagine talking to someone who doesn’t respond in any way — you can’t communicate at all. Same goes for your app.You must ensure that there is always some feedback for user actions, because it makes users feel in control. Visual feedbackIn real life, buttons, controls and objects respond to our interaction, and this is how people expect things to work. People expect a similar level of responsiveness from app elements.Visual feedback is also helpful when you need to inform users about results of an operation. You can use existing elements to deliver a feedback.Users want to know their current context in a system at any given time and apps shouldn’t keep them guessing — they should tell the user what’s happening via appropriate visual feedback. For frequent and minor actions, the response can be modest, while for infrequent and major actions, the response should be more substantial.Microcopy is the little bits of text that guide users through an experience. Microcopy examples are error messages, button labels, hint text. At a glance, these tiny clusters of words seem insignificant when compared to the overall app design. But surprisingly, they have a huge impact on conversions.A quick way to make your UI warmer and less mechanical is a human tone in the copy. If your product sounds human, it’s easier for people to trust you.How errors are communicated can have a huge impact on the way someone experiences your product. Often overlooked, an ill-constructed error message can fill users with frustration.A well-crafted error message, on the other hand, can turn a moment of frustration into a moment of delight. Thus, make error messages human, not technical, and suited to your audience.Microcopy is extremely contextual. That’s why it’s so valuable. It answers a very specific question people have and speaks to their concerns right on the spot. For example, microcopy can be fundamental in reassuring your users at the point of subscribing or sharing details. Whilst ‘not to spam/auto-tweet’ might be taken for granted by good marketers when asking for email address/access to the social network account connections, the user is less than sure. Thus, when people add their emails or connect their Twitter accounts, say “we hate spam as much as you do.”Whitespace (or negative space) is the areas of a design where there is no element placed by a designer. Elements of whitespace are space around images, margins, paddings, line-spacing and letter-spacing within text content. Although many may consider it a waste of valuable screen estate, whitespace is an essential element in user interface design.Clutter is bad. Cluttering your interface overloads your user with too much information: every added button, image, and line of text make the screen more complicated. If you don’t think any part of your design should be intentionally blank, take a look at example below and you’ll see what happens when too many objects competing for your attention.The power of white space comes from the limits of human attention and memory. Our short-term memory can hold a small amount of information (typically around 7 items or even less) in mind in an active, readily-available state for a short period of time (typically from 10 to 15 seconds, or sometimes up to a minute).If cluttering your interface overloads your user with too much information, then reducing the clutter will improve comprehension. Generous whitespace can make some of the messiest interfaces look inviting and simple. Whitespace reduces the amount of elements users see all at once and makes scanning much easier. The skill of using whitespace lies in providing your users with a digestible amount of content (chunks of content), then stripping away extraneous details.Whitespace creates the spaces around elements in the design to help them stand out or separate from the other elements. It helps communicate what’s most important and needs attention.Google Search homepage is a great example of using whitespace. The layout immediately facilitates the user goal by placing primary interaction element (search box) in front and center, with plenty of white space on either side to add emphasis.The law of proximity describes how the human eye perceives connections between visual elements. It states that objects near to each other appear similar. We can use whitespace to build perceived relationships between different elements. Take a look at this picture. Almost everyone sees two groups of dots, rather than simply 16 dots.Breaking the information up into appropriate groups can help make it feel more scannable and readable. In the form on the right, categorising the 15 fields into three groups makes the process feel easier. The amount of content is the same, but the impression on users is much different.Design with care. Each minor detail in your app’s UI deserves close attention because UX is the sum of all details working harmoniously:Thank you!Follow UX Planet: Twitter | FacebookOriginally published at babich.biz"
  },
  {
    "link": "https://medium.freecodecamp.com/looking-back-to-what-started-it-all-731ef5424aec?source=---------1-----------",
    "pic": "https://cdn-images-1.medium.com/fit/c/36/36/0*snmOZv18UKH2rM7V.jpeg",
    "author": "Nick Babich",
    "date": "Jan 27, 2015",
    "photo": "https://cdn-images-1.medium.com/max/800/0*KJlg8u5H_GnwVMMR.jpg",
    "head": "A Vision of Coding, Without Opening your Eyes",
    "contents": "Your product’s success is based on a combination of factors, but the overall user experience tops them all. When it comes down to designing a new app or a site, sticking to best practices is a solid way to go, but during the creation of the big picture, it’s fairly easy to skimp over design elements that feel like nice to have but not necessary. However, the difference between good and bad experiences often comes down to how thoughtful we can design these small details.In this article, I’ll focus on visual feedback, microcopy and whitespace and you’ll see why these little big details are just as important as the more obvious elements of your design, and how they help determine the success of your product.Visual feedback might be easily overlooked in the greater design scheme, but it actually hold the entire experience together. When there’s no feedback there’s no proper interaction. Imagine talking to someone who doesn’t respond in any way — you can’t communicate at all. Same goes for your app.You must ensure that there is always some feedback for user actions, because it makes users feel in control. Visual feedbackIn real life, buttons, controls and objects respond to our interaction, and this is how people expect things to work. People expect a similar level of responsiveness from app elements.Visual feedback is also helpful when you need to inform users about results of an operation. You can use existing elements to deliver a feedback.Users want to know their current context in a system at any given time and apps shouldn’t keep them guessing — they should tell the user what’s happening via appropriate visual feedback. For frequent and minor actions, the response can be modest, while for infrequent and major actions, the response should be more substantial.Microcopy is the little bits of text that guide users through an experience. Microcopy examples are error messages, button labels, hint text. At a glance, these tiny clusters of words seem insignificant when compared to the overall app design. But surprisingly, they have a huge impact on conversions.A quick way to make your UI warmer and less mechanical is a human tone in the copy. If your product sounds human, it’s easier for people to trust you.How errors are communicated can have a huge impact on the way someone experiences your product. Often overlooked, an ill-constructed error message can fill users with frustration.A well-crafted error message, on the other hand, can turn a moment of frustration into a moment of delight. Thus, make error messages human, not technical, and suited to your audience.Microcopy is extremely contextual. That’s why it’s so valuable. It answers a very specific question people have and speaks to their concerns right on the spot. For example, microcopy can be fundamental in reassuring your users at the point of subscribing or sharing details. Whilst ‘not to spam/auto-tweet’ might be taken for granted by good marketers when asking for email address/access to the social network account connections, the user is less than sure. Thus, when people add their emails or connect their Twitter accounts, say “we hate spam as much as you do.”Whitespace (or negative space) is the areas of a design where there is no element placed by a designer. Elements of whitespace are space around images, margins, paddings, line-spacing and letter-spacing within text content. Although many may consider it a waste of valuable screen estate, whitespace is an essential element in user interface design.Clutter is bad. Cluttering your interface overloads your user with too much information: every added button, image, and line of text make the screen more complicated. If you don’t think any part of your design should be intentionally blank, take a look at example below and you’ll see what happens when too many objects competing for your attention.The power of white space comes from the limits of human attention and memory. Our short-term memory can hold a small amount of information (typically around 7 items or even less) in mind in an active, readily-available state for a short period of time (typically from 10 to 15 seconds, or sometimes up to a minute).If cluttering your interface overloads your user with too much information, then reducing the clutter will improve comprehension. Generous whitespace can make some of the messiest interfaces look inviting and simple. Whitespace reduces the amount of elements users see all at once and makes scanning much easier. The skill of using whitespace lies in providing your users with a digestible amount of content (chunks of content), then stripping away extraneous details.Whitespace creates the spaces around elements in the design to help them stand out or separate from the other elements. It helps communicate what’s most important and needs attention.Google Search homepage is a great example of using whitespace. The layout immediately facilitates the user goal by placing primary interaction element (search box) in front and center, with plenty of white space on either side to add emphasis.The law of proximity describes how the human eye perceives connections between visual elements. It states that objects near to each other appear similar. We can use whitespace to build perceived relationships between different elements. Take a look at this picture. Almost everyone sees two groups of dots, rather than simply 16 dots.Breaking the information up into appropriate groups can help make it feel more scannable and readable. In the form on the right, categorising the 15 fields into three groups makes the process feel easier. The amount of content is the same, but the impression on users is much different.Design with care. Each minor detail in your app’s UI deserves close attention because UX is the sum of all details working harmoniously:Thank you!Follow UX Planet: Twitter | FacebookOriginally published at babich.bizI’m a coder. I’m also blind. Blind as a bat, you might say. And I was born this way. When I mention this to my fellow human beings — the ones who’ve never suffered any form of visual impairment — they usually ask one of following questions:I get these questions again and again. So let me answer these three questions in this blog post. I’ll try and sketch out an image for those of you who are curious about accessibility, and how blind people use computers to code, and to do the work of the 21st century.I like this question, because it allows me to immediately explain how blind people actually use computers. A lot of people are under the impression that blind people require specially adapted computers in order to get anything done. Even some of my fellow Visually Impaired Persons (VIPs) tend to think this. Well let me debunk this myth right here and now. I am currently typing this on a normal Dell Inspiron 15r SE notebook, which can be bought in any laptop store that sells (somewhat less recent) laptops. The machine runs windows 8 (not my personal choice, but UEFI is too much of a pain to downgrade). All I did to adapt it was install an open-source screen reader called NVDA. A screen reader basically, at its most basic level — wait for it — reads the screen. It tells you the textual content of the screen with a synthesized text-to-speech Siri-like voice. Screen readers also allow for the use of a braille display, a device that consists of a line of refreshable braille cells that can form letters according to what content is highlighted on the screen.This is really all the adaptation a blind computer user needs. Using this program, I can do many things you probably wouldn’t imagine being able to do with your eyes closed, such as:The reason I’m naming all these mainstream technologies is to show you that I can use them just like people who aren’t ocularly challenged. If you’re writing the next big application, with a stunning UI and a great workflow, I humbly ask you to consider accessibility as part of the equation. In this day and age, there’s really no reason not to use the UI toolkits available. It’s a lot easier than you may think. Yes, these include the Android Activities, iOS NsViews and HTML5 widgets you may be thinking of. I joined Free Code Camp a few weeks back and really loved the concept. I’ve been pursuing a degree in Computer Science for the last few years, and had failed a semester that involved a lot of work with the MEAN stack. So I was really happy to find such an amazing community to be a part of and learn with. I’m sure I’ll pass my semester with flying colors this time. I sadly ran into accessibility issues when working through the by now famous Dash tutorials by General Assembly. The tutorials are undoubtedly good, but were completely unreadable for me because they chose to embed all their text in image slides that lack any textual description or content for screen readers to work with. Recall that screen readers read out textual content of the screen. They aren’t smart enough to interpret graphics. Fortunately, some fellow campers at the Free Code Camp were sympathetic towards my plight and volunteered to transcribe all these slides for me. This offer left me ‘flabbergasted’, as our dear western neighbors across the sea would say. I’m very grateful for the work these people have done to further my studying. You guys know who you are. Thanks a lot!If left paren x equals five right paren left brace print left paren quote hello world exclaim quote right paren right brace. This is how a typical if-block in a Java-ish programming language would be read to me. You can see that it’s rather verbose. I tend to turn off the notifications for parenthesis and brackets until I find I need to match brackets while debugging, so that I don’t go crazy from the rather wordy descriptions of these signs. Others have solved this problem by substituting the default ‘left brace’ for something like ‘lace’ or ‘begin’, just to save a few milliseconds. The rate of speech is extremely fast for people who aren’t used to it.For those of you who can’t follow this, it’s my computer reading out the first bit of this very blog post that I’m writing in NotePad++. So, how I code doesn’t actually differ all that much from how others code. I’ve learned how to touch type, and mentally conceptualize my code so that I can work with it just like you guys do. The only difference is that I barely ever use a mouse for anything. I tend to stick with hotkeys and the command line instead. Sadly though, in this field, all is not well. Premier tools that coders use every day, like the IntelliJ editor, as well as all its offshoots (PHPStorm, WebStorm, PyCharm), are completely inaccessible, due simply to the fact that the developers of these programs have not adhered to the accessibility guidelines. They’ve failed to give screen readers textual labels or accessibility descriptions to work with. The same goes for applications like SourceTree, which is slowly getting better, but is still a pain to use. I therefore have to keep looking for tutorials, programs and tools that are accessible, and cannot simply pick up any off-the-shelf IDE.I promised to answer all three questions, so I’ll keep that promise. Don’t expect anything too resounding, though. I dream just like you guys do. My mind translates experiences and impulses I’ve received during the day into dreams I have at night. The difference being that I don’t actually see anything. Instead, I hear, smell and feel everything, just like in real life. The reason for this is simple: dreams based on visual imagery pull from your already stored visual knowledge to construct that visual imagery. Since I’ve been blind since birth, I have no visual frame of reference. The visual portion of my dreams run into a big fat 404 error: image not found.A Free Code Camp volunteer asked me to write this blog post to share my way of doing things with the world. After the welcome I’ve received from this community, I was all too happy to write this. I really hope you guys have learned something from it. I could talk about this for hours, and this article has already grown far longer than I initially planned. If you have questions, come find me in the Free Code Camp chatrooms. I am Zersiax there, and I can be found by that name on Twitter as well.Thanks for reading this. I’ll see you later! (Sorry. I really couldn’t resist that one) :)I thought this would be fitting to repost — as my first-ever Medium post — the article that threw my life for a loop one year ago, back in January 2015."
  },
  {
    "link": "https://medium.com/uber-design/uber-navigation-f662e7611f3?source=---------2-----------",
    "pic": "https://cdn-images-1.medium.com/fit/c/36/36/1*BKWSEsJYXZy7TDFhv2yPCA.jpeg",
    "author": "",
    "date": "Mar 15",
    "photo": "https://cdn-images-1.medium.com/max/800/1*xpXF0yuKlzkce1hPSrqxdw.gif",
    "head": "Uber Navigation",
    "contents": "Your product’s success is based on a combination of factors, but the overall user experience tops them all. When it comes down to designing a new app or a site, sticking to best practices is a solid way to go, but during the creation of the big picture, it’s fairly easy to skimp over design elements that feel like nice to have but not necessary. However, the difference between good and bad experiences often comes down to how thoughtful we can design these small details.In this article, I’ll focus on visual feedback, microcopy and whitespace and you’ll see why these little big details are just as important as the more obvious elements of your design, and how they help determine the success of your product.Visual feedback might be easily overlooked in the greater design scheme, but it actually hold the entire experience together. When there’s no feedback there’s no proper interaction. Imagine talking to someone who doesn’t respond in any way — you can’t communicate at all. Same goes for your app.You must ensure that there is always some feedback for user actions, because it makes users feel in control. Visual feedbackIn real life, buttons, controls and objects respond to our interaction, and this is how people expect things to work. People expect a similar level of responsiveness from app elements.Visual feedback is also helpful when you need to inform users about results of an operation. You can use existing elements to deliver a feedback.Users want to know their current context in a system at any given time and apps shouldn’t keep them guessing — they should tell the user what’s happening via appropriate visual feedback. For frequent and minor actions, the response can be modest, while for infrequent and major actions, the response should be more substantial.Microcopy is the little bits of text that guide users through an experience. Microcopy examples are error messages, button labels, hint text. At a glance, these tiny clusters of words seem insignificant when compared to the overall app design. But surprisingly, they have a huge impact on conversions.A quick way to make your UI warmer and less mechanical is a human tone in the copy. If your product sounds human, it’s easier for people to trust you.How errors are communicated can have a huge impact on the way someone experiences your product. Often overlooked, an ill-constructed error message can fill users with frustration.A well-crafted error message, on the other hand, can turn a moment of frustration into a moment of delight. Thus, make error messages human, not technical, and suited to your audience.Microcopy is extremely contextual. That’s why it’s so valuable. It answers a very specific question people have and speaks to their concerns right on the spot. For example, microcopy can be fundamental in reassuring your users at the point of subscribing or sharing details. Whilst ‘not to spam/auto-tweet’ might be taken for granted by good marketers when asking for email address/access to the social network account connections, the user is less than sure. Thus, when people add their emails or connect their Twitter accounts, say “we hate spam as much as you do.”Whitespace (or negative space) is the areas of a design where there is no element placed by a designer. Elements of whitespace are space around images, margins, paddings, line-spacing and letter-spacing within text content. Although many may consider it a waste of valuable screen estate, whitespace is an essential element in user interface design.Clutter is bad. Cluttering your interface overloads your user with too much information: every added button, image, and line of text make the screen more complicated. If you don’t think any part of your design should be intentionally blank, take a look at example below and you’ll see what happens when too many objects competing for your attention.The power of white space comes from the limits of human attention and memory. Our short-term memory can hold a small amount of information (typically around 7 items or even less) in mind in an active, readily-available state for a short period of time (typically from 10 to 15 seconds, or sometimes up to a minute).If cluttering your interface overloads your user with too much information, then reducing the clutter will improve comprehension. Generous whitespace can make some of the messiest interfaces look inviting and simple. Whitespace reduces the amount of elements users see all at once and makes scanning much easier. The skill of using whitespace lies in providing your users with a digestible amount of content (chunks of content), then stripping away extraneous details.Whitespace creates the spaces around elements in the design to help them stand out or separate from the other elements. It helps communicate what’s most important and needs attention.Google Search homepage is a great example of using whitespace. The layout immediately facilitates the user goal by placing primary interaction element (search box) in front and center, with plenty of white space on either side to add emphasis.The law of proximity describes how the human eye perceives connections between visual elements. It states that objects near to each other appear similar. We can use whitespace to build perceived relationships between different elements. Take a look at this picture. Almost everyone sees two groups of dots, rather than simply 16 dots.Breaking the information up into appropriate groups can help make it feel more scannable and readable. In the form on the right, categorising the 15 fields into three groups makes the process feel easier. The amount of content is the same, but the impression on users is much different.Design with care. Each minor detail in your app’s UI deserves close attention because UX is the sum of all details working harmoniously:Thank you!Follow UX Planet: Twitter | FacebookOriginally published at babich.bizI’m a coder. I’m also blind. Blind as a bat, you might say. And I was born this way. When I mention this to my fellow human beings — the ones who’ve never suffered any form of visual impairment — they usually ask one of following questions:I get these questions again and again. So let me answer these three questions in this blog post. I’ll try and sketch out an image for those of you who are curious about accessibility, and how blind people use computers to code, and to do the work of the 21st century.I like this question, because it allows me to immediately explain how blind people actually use computers. A lot of people are under the impression that blind people require specially adapted computers in order to get anything done. Even some of my fellow Visually Impaired Persons (VIPs) tend to think this. Well let me debunk this myth right here and now. I am currently typing this on a normal Dell Inspiron 15r SE notebook, which can be bought in any laptop store that sells (somewhat less recent) laptops. The machine runs windows 8 (not my personal choice, but UEFI is too much of a pain to downgrade). All I did to adapt it was install an open-source screen reader called NVDA. A screen reader basically, at its most basic level — wait for it — reads the screen. It tells you the textual content of the screen with a synthesized text-to-speech Siri-like voice. Screen readers also allow for the use of a braille display, a device that consists of a line of refreshable braille cells that can form letters according to what content is highlighted on the screen.This is really all the adaptation a blind computer user needs. Using this program, I can do many things you probably wouldn’t imagine being able to do with your eyes closed, such as:The reason I’m naming all these mainstream technologies is to show you that I can use them just like people who aren’t ocularly challenged. If you’re writing the next big application, with a stunning UI and a great workflow, I humbly ask you to consider accessibility as part of the equation. In this day and age, there’s really no reason not to use the UI toolkits available. It’s a lot easier than you may think. Yes, these include the Android Activities, iOS NsViews and HTML5 widgets you may be thinking of. I joined Free Code Camp a few weeks back and really loved the concept. I’ve been pursuing a degree in Computer Science for the last few years, and had failed a semester that involved a lot of work with the MEAN stack. So I was really happy to find such an amazing community to be a part of and learn with. I’m sure I’ll pass my semester with flying colors this time. I sadly ran into accessibility issues when working through the by now famous Dash tutorials by General Assembly. The tutorials are undoubtedly good, but were completely unreadable for me because they chose to embed all their text in image slides that lack any textual description or content for screen readers to work with. Recall that screen readers read out textual content of the screen. They aren’t smart enough to interpret graphics. Fortunately, some fellow campers at the Free Code Camp were sympathetic towards my plight and volunteered to transcribe all these slides for me. This offer left me ‘flabbergasted’, as our dear western neighbors across the sea would say. I’m very grateful for the work these people have done to further my studying. You guys know who you are. Thanks a lot!If left paren x equals five right paren left brace print left paren quote hello world exclaim quote right paren right brace. This is how a typical if-block in a Java-ish programming language would be read to me. You can see that it’s rather verbose. I tend to turn off the notifications for parenthesis and brackets until I find I need to match brackets while debugging, so that I don’t go crazy from the rather wordy descriptions of these signs. Others have solved this problem by substituting the default ‘left brace’ for something like ‘lace’ or ‘begin’, just to save a few milliseconds. The rate of speech is extremely fast for people who aren’t used to it.For those of you who can’t follow this, it’s my computer reading out the first bit of this very blog post that I’m writing in NotePad++. So, how I code doesn’t actually differ all that much from how others code. I’ve learned how to touch type, and mentally conceptualize my code so that I can work with it just like you guys do. The only difference is that I barely ever use a mouse for anything. I tend to stick with hotkeys and the command line instead. Sadly though, in this field, all is not well. Premier tools that coders use every day, like the IntelliJ editor, as well as all its offshoots (PHPStorm, WebStorm, PyCharm), are completely inaccessible, due simply to the fact that the developers of these programs have not adhered to the accessibility guidelines. They’ve failed to give screen readers textual labels or accessibility descriptions to work with. The same goes for applications like SourceTree, which is slowly getting better, but is still a pain to use. I therefore have to keep looking for tutorials, programs and tools that are accessible, and cannot simply pick up any off-the-shelf IDE.I promised to answer all three questions, so I’ll keep that promise. Don’t expect anything too resounding, though. I dream just like you guys do. My mind translates experiences and impulses I’ve received during the day into dreams I have at night. The difference being that I don’t actually see anything. Instead, I hear, smell and feel everything, just like in real life. The reason for this is simple: dreams based on visual imagery pull from your already stored visual knowledge to construct that visual imagery. Since I’ve been blind since birth, I have no visual frame of reference. The visual portion of my dreams run into a big fat 404 error: image not found.A Free Code Camp volunteer asked me to write this blog post to share my way of doing things with the world. After the welcome I’ve received from this community, I was all too happy to write this. I really hope you guys have learned something from it. I could talk about this for hours, and this article has already grown far longer than I initially planned. If you have questions, come find me in the Free Code Camp chatrooms. I am Zersiax there, and I can be found by that name on Twitter as well.Thanks for reading this. I’ll see you later! (Sorry. I really couldn’t resist that one) :)I thought this would be fitting to repost — as my first-ever Medium post — the article that threw my life for a loop one year ago, back in January 2015.Y ou sit in your car, listening to a light rain ping quietly down on the hood. You’ve just finished your fourth trip of the night, and you sit back and relax. Not for long though, it’s a busy night and you accept another pickup request close by. As navigation begins, you check your mirrors, shift into drive, and pull out onto the road towards a new destination. You work your way across a few lanes of heavy traffic to make that first left coming up. After more lights and turns, you arrive at a busy pickup point and look for a safe space to pull over. Out of the crowd on the sidewalk, a person waves and heads your way.You’re about to find out where you’re going next.On the driver team at Uber, one of our jobs is to take the pressure off of drivers, so that they can focus on smooth and stress-free rides for everybody. We want to make sure that drivers have the best features possible directly in-app, and one of the most important features is a navigation system. So we started with a basic question:If you’re browsing for a new restaurant for lunch, or trying to find a lecture hall on a college campus, you’ll have different mapping needs than if you’re in the mountains on a two-day hike. And, if you’re commuting to work on a familiar daily route, or driving to a friend’s birthday party, your navigation needs are different from people driving with Uber. Why are one-size-fits-all digital maps not a good fit for Uber?It all boils down to this:For most drivers in most situations, your trip is a simple one: you’ve got a starting point, a destination, and the best route between the two. The end.If you’re driving with Uber, however, it’s all about that magic moment where a car and a passenger meet. Then you travel together to a new destination, and when your passenger leaves your car, you’re off to the next meeting point. If you are a driver on an uberPool trip, your route might have several overlapping pickups and dropoffs. Throw deliveries into the mix — where you might need to park and walk inside for a pickup — and navigation can get incredibly complicated.When it came to something as central as navigation, we knew how important it was to get things right. Uber is able to move fast with features, but for the navigation overhaul, our pace was much more deliberate.Committing to the long haul meant that we could dive deeply into the needs of drivers. We conducted driver interviews. We rode along with them to watch and listen to their pain points. We held in-office forums and gathered map and navigation related feedback. We shared prototypes, observed drivers interacting with them, and listened to their likes and dislikes. We set up an eye-tracking rig and analyzed how a driver’s eyes interact with the environment vs. a device screen. We built a car simulator in our office, which we connected to a gaming wheel controller, a video of typical driving scenarios, and a timed navigation prototype. We even built a physical map of Amsterdam out of paper.But we didn’t stop there. We sent our team across the US and all over the world with navigation prototypes and cameras to see what would happen when rubber met the road.It’s hard to overstate how valuable this first-person testing was. We understood that we needed a mapping + navigation tool that would be as useful over the canals of Amsterdam and through the tunnels of Boston as it would in the jammed streets of Jakarta or the one-way avenues of NYC. Day or night, uberX or uberPOOL, it needed to serve the unique needs of drivers.Unlike traditional navigation apps, Uber Navigation has to help its users answer the question “What’s next?”. Once a driver successfully completes one trip, it’s important that navigation is ready with the best route for the next trip.Uber Navigation also needs to differentiate between types of locations and activities, so we designed distinct visuals for the variety of actions a driver might take on different legs of a trip. Custom cartography, maneuver iconography, pins, side-of-street-indicators, route line previews, and camera animations all work together to explain the journey.Take the “3-Foot-1-Second” Rule: drivers are looking at a smartphone-sized screen from about three feet away, for about one second at a time. This means that “glanceability” and “tappability” are priorities. Designing the new navigation experience was all about answering the question “what is the essential information that the user needs right now?” Everything else had to take a backseat.For gestures, we wanted drivers to have freedom, but also minimal need to interact while driving. We do enable a driver to pan and zoom if they choose, but we also made sure to build in an effortless single tap gesture to toggle between an overview state and a first person navigation, or to inspect the destination point.One of our essential new navigation features is Night Mode. Many people drive with Uber at night, and sometimes for hours at a time. The default day settings can cause eye-strain as a driver readjusts from the bright screen to the dark streets outside. Night Mode protects drivers from light pollution that would otherwise be a real ergonomic and safety hazard.For Night Mode, we wanted a subdued color palette. Designers sat in a windowless, dark room and analyzed multiple color schemes. We were amazed by how different they looked in an unlit room compared to a normal bright conference room. We took our favorite options out on night-time drive tests, and from there we pushed and pulled values until the guidance UI, map UI, and map styles all felt harmonious.Uber Navigation is custom tailored for drivers, and we’re not done yet. Every day we’re collecting great constructive feedback from drivers, and we’ll be prioritizing their feedback in upcoming versions. Plus, now that we’ve rolled out our starting lineup, we’re excited for all of the design possibilities to come.We are so proud of everyone who made this happen. And while this post is design-focused, we want to recognize over a year of hard work by designers, engineers, researchers, and product managers. Most of all, we’d like to thank the drivers for their invaluable feedback. Thank you!Are you a map design enthusiast, routing wonk, driver? Have any thoughts about the new navigation? Let us know what you think in the comments below!ByEvelyn KimCady WachsmanChristine TaoBo Paweena AttayadmawittayaMap data source © TomTom"
  },
  {
    "link": "https://medium.muz.li/best-design-advice-no-one-ever-gave-me-92acf6b0858a?source=---------3-----------",
    "pic": "https://cdn-images-1.medium.com/fit/c/36/36/1*Y25EVwM-Uy-DpA27F1PwzQ.jpeg",
    "author": "Florian Beijers",
    "date": "Mar 17",
    "photo": "https://cdn-images-1.medium.com/max/1000/1*LwSKN80sJ_nZ-a-lJXyMkQ.jpeg",
    "head": "Best Design Advice No One Ever Gave Me",
    "contents": "Your product’s success is based on a combination of factors, but the overall user experience tops them all. When it comes down to designing a new app or a site, sticking to best practices is a solid way to go, but during the creation of the big picture, it’s fairly easy to skimp over design elements that feel like nice to have but not necessary. However, the difference between good and bad experiences often comes down to how thoughtful we can design these small details.In this article, I’ll focus on visual feedback, microcopy and whitespace and you’ll see why these little big details are just as important as the more obvious elements of your design, and how they help determine the success of your product.Visual feedback might be easily overlooked in the greater design scheme, but it actually hold the entire experience together. When there’s no feedback there’s no proper interaction. Imagine talking to someone who doesn’t respond in any way — you can’t communicate at all. Same goes for your app.You must ensure that there is always some feedback for user actions, because it makes users feel in control. Visual feedbackIn real life, buttons, controls and objects respond to our interaction, and this is how people expect things to work. People expect a similar level of responsiveness from app elements.Visual feedback is also helpful when you need to inform users about results of an operation. You can use existing elements to deliver a feedback.Users want to know their current context in a system at any given time and apps shouldn’t keep them guessing — they should tell the user what’s happening via appropriate visual feedback. For frequent and minor actions, the response can be modest, while for infrequent and major actions, the response should be more substantial.Microcopy is the little bits of text that guide users through an experience. Microcopy examples are error messages, button labels, hint text. At a glance, these tiny clusters of words seem insignificant when compared to the overall app design. But surprisingly, they have a huge impact on conversions.A quick way to make your UI warmer and less mechanical is a human tone in the copy. If your product sounds human, it’s easier for people to trust you.How errors are communicated can have a huge impact on the way someone experiences your product. Often overlooked, an ill-constructed error message can fill users with frustration.A well-crafted error message, on the other hand, can turn a moment of frustration into a moment of delight. Thus, make error messages human, not technical, and suited to your audience.Microcopy is extremely contextual. That’s why it’s so valuable. It answers a very specific question people have and speaks to their concerns right on the spot. For example, microcopy can be fundamental in reassuring your users at the point of subscribing or sharing details. Whilst ‘not to spam/auto-tweet’ might be taken for granted by good marketers when asking for email address/access to the social network account connections, the user is less than sure. Thus, when people add their emails or connect their Twitter accounts, say “we hate spam as much as you do.”Whitespace (or negative space) is the areas of a design where there is no element placed by a designer. Elements of whitespace are space around images, margins, paddings, line-spacing and letter-spacing within text content. Although many may consider it a waste of valuable screen estate, whitespace is an essential element in user interface design.Clutter is bad. Cluttering your interface overloads your user with too much information: every added button, image, and line of text make the screen more complicated. If you don’t think any part of your design should be intentionally blank, take a look at example below and you’ll see what happens when too many objects competing for your attention.The power of white space comes from the limits of human attention and memory. Our short-term memory can hold a small amount of information (typically around 7 items or even less) in mind in an active, readily-available state for a short period of time (typically from 10 to 15 seconds, or sometimes up to a minute).If cluttering your interface overloads your user with too much information, then reducing the clutter will improve comprehension. Generous whitespace can make some of the messiest interfaces look inviting and simple. Whitespace reduces the amount of elements users see all at once and makes scanning much easier. The skill of using whitespace lies in providing your users with a digestible amount of content (chunks of content), then stripping away extraneous details.Whitespace creates the spaces around elements in the design to help them stand out or separate from the other elements. It helps communicate what’s most important and needs attention.Google Search homepage is a great example of using whitespace. The layout immediately facilitates the user goal by placing primary interaction element (search box) in front and center, with plenty of white space on either side to add emphasis.The law of proximity describes how the human eye perceives connections between visual elements. It states that objects near to each other appear similar. We can use whitespace to build perceived relationships between different elements. Take a look at this picture. Almost everyone sees two groups of dots, rather than simply 16 dots.Breaking the information up into appropriate groups can help make it feel more scannable and readable. In the form on the right, categorising the 15 fields into three groups makes the process feel easier. The amount of content is the same, but the impression on users is much different.Design with care. Each minor detail in your app’s UI deserves close attention because UX is the sum of all details working harmoniously:Thank you!Follow UX Planet: Twitter | FacebookOriginally published at babich.bizI’m a coder. I’m also blind. Blind as a bat, you might say. And I was born this way. When I mention this to my fellow human beings — the ones who’ve never suffered any form of visual impairment — they usually ask one of following questions:I get these questions again and again. So let me answer these three questions in this blog post. I’ll try and sketch out an image for those of you who are curious about accessibility, and how blind people use computers to code, and to do the work of the 21st century.I like this question, because it allows me to immediately explain how blind people actually use computers. A lot of people are under the impression that blind people require specially adapted computers in order to get anything done. Even some of my fellow Visually Impaired Persons (VIPs) tend to think this. Well let me debunk this myth right here and now. I am currently typing this on a normal Dell Inspiron 15r SE notebook, which can be bought in any laptop store that sells (somewhat less recent) laptops. The machine runs windows 8 (not my personal choice, but UEFI is too much of a pain to downgrade). All I did to adapt it was install an open-source screen reader called NVDA. A screen reader basically, at its most basic level — wait for it — reads the screen. It tells you the textual content of the screen with a synthesized text-to-speech Siri-like voice. Screen readers also allow for the use of a braille display, a device that consists of a line of refreshable braille cells that can form letters according to what content is highlighted on the screen.This is really all the adaptation a blind computer user needs. Using this program, I can do many things you probably wouldn’t imagine being able to do with your eyes closed, such as:The reason I’m naming all these mainstream technologies is to show you that I can use them just like people who aren’t ocularly challenged. If you’re writing the next big application, with a stunning UI and a great workflow, I humbly ask you to consider accessibility as part of the equation. In this day and age, there’s really no reason not to use the UI toolkits available. It’s a lot easier than you may think. Yes, these include the Android Activities, iOS NsViews and HTML5 widgets you may be thinking of. I joined Free Code Camp a few weeks back and really loved the concept. I’ve been pursuing a degree in Computer Science for the last few years, and had failed a semester that involved a lot of work with the MEAN stack. So I was really happy to find such an amazing community to be a part of and learn with. I’m sure I’ll pass my semester with flying colors this time. I sadly ran into accessibility issues when working through the by now famous Dash tutorials by General Assembly. The tutorials are undoubtedly good, but were completely unreadable for me because they chose to embed all their text in image slides that lack any textual description or content for screen readers to work with. Recall that screen readers read out textual content of the screen. They aren’t smart enough to interpret graphics. Fortunately, some fellow campers at the Free Code Camp were sympathetic towards my plight and volunteered to transcribe all these slides for me. This offer left me ‘flabbergasted’, as our dear western neighbors across the sea would say. I’m very grateful for the work these people have done to further my studying. You guys know who you are. Thanks a lot!If left paren x equals five right paren left brace print left paren quote hello world exclaim quote right paren right brace. This is how a typical if-block in a Java-ish programming language would be read to me. You can see that it’s rather verbose. I tend to turn off the notifications for parenthesis and brackets until I find I need to match brackets while debugging, so that I don’t go crazy from the rather wordy descriptions of these signs. Others have solved this problem by substituting the default ‘left brace’ for something like ‘lace’ or ‘begin’, just to save a few milliseconds. The rate of speech is extremely fast for people who aren’t used to it.For those of you who can’t follow this, it’s my computer reading out the first bit of this very blog post that I’m writing in NotePad++. So, how I code doesn’t actually differ all that much from how others code. I’ve learned how to touch type, and mentally conceptualize my code so that I can work with it just like you guys do. The only difference is that I barely ever use a mouse for anything. I tend to stick with hotkeys and the command line instead. Sadly though, in this field, all is not well. Premier tools that coders use every day, like the IntelliJ editor, as well as all its offshoots (PHPStorm, WebStorm, PyCharm), are completely inaccessible, due simply to the fact that the developers of these programs have not adhered to the accessibility guidelines. They’ve failed to give screen readers textual labels or accessibility descriptions to work with. The same goes for applications like SourceTree, which is slowly getting better, but is still a pain to use. I therefore have to keep looking for tutorials, programs and tools that are accessible, and cannot simply pick up any off-the-shelf IDE.I promised to answer all three questions, so I’ll keep that promise. Don’t expect anything too resounding, though. I dream just like you guys do. My mind translates experiences and impulses I’ve received during the day into dreams I have at night. The difference being that I don’t actually see anything. Instead, I hear, smell and feel everything, just like in real life. The reason for this is simple: dreams based on visual imagery pull from your already stored visual knowledge to construct that visual imagery. Since I’ve been blind since birth, I have no visual frame of reference. The visual portion of my dreams run into a big fat 404 error: image not found.A Free Code Camp volunteer asked me to write this blog post to share my way of doing things with the world. After the welcome I’ve received from this community, I was all too happy to write this. I really hope you guys have learned something from it. I could talk about this for hours, and this article has already grown far longer than I initially planned. If you have questions, come find me in the Free Code Camp chatrooms. I am Zersiax there, and I can be found by that name on Twitter as well.Thanks for reading this. I’ll see you later! (Sorry. I really couldn’t resist that one) :)I thought this would be fitting to repost — as my first-ever Medium post — the article that threw my life for a loop one year ago, back in January 2015.Y ou sit in your car, listening to a light rain ping quietly down on the hood. You’ve just finished your fourth trip of the night, and you sit back and relax. Not for long though, it’s a busy night and you accept another pickup request close by. As navigation begins, you check your mirrors, shift into drive, and pull out onto the road towards a new destination. You work your way across a few lanes of heavy traffic to make that first left coming up. After more lights and turns, you arrive at a busy pickup point and look for a safe space to pull over. Out of the crowd on the sidewalk, a person waves and heads your way.You’re about to find out where you’re going next.On the driver team at Uber, one of our jobs is to take the pressure off of drivers, so that they can focus on smooth and stress-free rides for everybody. We want to make sure that drivers have the best features possible directly in-app, and one of the most important features is a navigation system. So we started with a basic question:If you’re browsing for a new restaurant for lunch, or trying to find a lecture hall on a college campus, you’ll have different mapping needs than if you’re in the mountains on a two-day hike. And, if you’re commuting to work on a familiar daily route, or driving to a friend’s birthday party, your navigation needs are different from people driving with Uber. Why are one-size-fits-all digital maps not a good fit for Uber?It all boils down to this:For most drivers in most situations, your trip is a simple one: you’ve got a starting point, a destination, and the best route between the two. The end.If you’re driving with Uber, however, it’s all about that magic moment where a car and a passenger meet. Then you travel together to a new destination, and when your passenger leaves your car, you’re off to the next meeting point. If you are a driver on an uberPool trip, your route might have several overlapping pickups and dropoffs. Throw deliveries into the mix — where you might need to park and walk inside for a pickup — and navigation can get incredibly complicated.When it came to something as central as navigation, we knew how important it was to get things right. Uber is able to move fast with features, but for the navigation overhaul, our pace was much more deliberate.Committing to the long haul meant that we could dive deeply into the needs of drivers. We conducted driver interviews. We rode along with them to watch and listen to their pain points. We held in-office forums and gathered map and navigation related feedback. We shared prototypes, observed drivers interacting with them, and listened to their likes and dislikes. We set up an eye-tracking rig and analyzed how a driver’s eyes interact with the environment vs. a device screen. We built a car simulator in our office, which we connected to a gaming wheel controller, a video of typical driving scenarios, and a timed navigation prototype. We even built a physical map of Amsterdam out of paper.But we didn’t stop there. We sent our team across the US and all over the world with navigation prototypes and cameras to see what would happen when rubber met the road.It’s hard to overstate how valuable this first-person testing was. We understood that we needed a mapping + navigation tool that would be as useful over the canals of Amsterdam and through the tunnels of Boston as it would in the jammed streets of Jakarta or the one-way avenues of NYC. Day or night, uberX or uberPOOL, it needed to serve the unique needs of drivers.Unlike traditional navigation apps, Uber Navigation has to help its users answer the question “What’s next?”. Once a driver successfully completes one trip, it’s important that navigation is ready with the best route for the next trip.Uber Navigation also needs to differentiate between types of locations and activities, so we designed distinct visuals for the variety of actions a driver might take on different legs of a trip. Custom cartography, maneuver iconography, pins, side-of-street-indicators, route line previews, and camera animations all work together to explain the journey.Take the “3-Foot-1-Second” Rule: drivers are looking at a smartphone-sized screen from about three feet away, for about one second at a time. This means that “glanceability” and “tappability” are priorities. Designing the new navigation experience was all about answering the question “what is the essential information that the user needs right now?” Everything else had to take a backseat.For gestures, we wanted drivers to have freedom, but also minimal need to interact while driving. We do enable a driver to pan and zoom if they choose, but we also made sure to build in an effortless single tap gesture to toggle between an overview state and a first person navigation, or to inspect the destination point.One of our essential new navigation features is Night Mode. Many people drive with Uber at night, and sometimes for hours at a time. The default day settings can cause eye-strain as a driver readjusts from the bright screen to the dark streets outside. Night Mode protects drivers from light pollution that would otherwise be a real ergonomic and safety hazard.For Night Mode, we wanted a subdued color palette. Designers sat in a windowless, dark room and analyzed multiple color schemes. We were amazed by how different they looked in an unlit room compared to a normal bright conference room. We took our favorite options out on night-time drive tests, and from there we pushed and pulled values until the guidance UI, map UI, and map styles all felt harmonious.Uber Navigation is custom tailored for drivers, and we’re not done yet. Every day we’re collecting great constructive feedback from drivers, and we’ll be prioritizing their feedback in upcoming versions. Plus, now that we’ve rolled out our starting lineup, we’re excited for all of the design possibilities to come.We are so proud of everyone who made this happen. And while this post is design-focused, we want to recognize over a year of hard work by designers, engineers, researchers, and product managers. Most of all, we’d like to thank the drivers for their invaluable feedback. Thank you!Are you a map design enthusiast, routing wonk, driver? Have any thoughts about the new navigation? Let us know what you think in the comments below!ByEvelyn KimCady WachsmanChristine TaoBo Paweena AttayadmawittayaMap data source © TomTomThroughout life, you hear the cheesy saying, “quality over quantity.” In most situations this is good advice. Not in the design world.To be clear, this isn’t an excuse to show 10 half-assed designs. This means, instead of showing one design you believe to be perfect, show 3 great ideas. The ampersand in the title of this section is important — we’re trying to strike a balance and deliver on both.Time for a real-world example: Most projects start with a list of product requirements. The people who come up with the requirements usually have an idea of how they believe the product should look (whether they tell you or not). Quantity and quality comes into play when there are differing opinions about implementation. The best way to keep the project moving is to show at least two examples:Even if you know option 1 won’t work in your head, showing the initial design is critical. Stakeholders won’t be satisfied until they can actually see its shortcomings. Usually a mashup of the two concepts will be the final outcome, but that’s better than executing a design you disagree with.You could have the world’s best design, but if you don’t know how to explain the problem being addressed and the reason for your design decisions, the design will never get approved. Context is king when it comes to pitching your idea or concept to others.There are two easy steps that will help you give a great presentation:If all you do is show your final design without providing context, people may not understand how you arrived at your conclusion and ask you to explore various other approaches. At that point, defending your work and pointing out the flaws in their suggestions might sound more defensive than you would like.This is something that is very important to me and a major part of being in a creative profession. I always make it a priority to learn new skills (software, leadership, dev languages, etc.) — whatever I need to continue to grow as a designer.I don’t buy the excuse that people are too busy to learn, because almost everyone has some free time at some point in the day. It comes down to what you do in that free time.At my first job I learned how to write html, css and some basic js and became a “developer.” When I took my second job I learned how to make illustrations and add animations to my designs. At my current job, I’m learning how to communicate my thoughts more clearly and build prototypes to better demonstrate my designs.I never want to get to a point in my career or life, when I have the feeling that there is no more room for growth or learning. That’s why I am constantly striving to develop new skills whenever I can.Trendy words/designs/clothes, etc. are exactly that: trends. They will, without a doubt, die out and look dated (Remember skeumorphic design). I try to avoid incorporating short-lived trends whenever I can in life and in my career.Sometimes, you can get caught up trying to get more likes or favorites or whatever it may be, by following trends. I see tons of concepts with text or buttons overflowing past the background a random distance. Or I see a title that fits perfectly with the image designers chose but if any other image was used, the same layout would never work. Yet these shots have hundreds of likes…Disclaimer: I understand dribbble and other sites like it are meant to somewhat of a creative release for people. Therefore some of the work is strictly for fun and was never meant to be used in the real world. I’m not saying trying new things and exploring new styles is bad — but it’s not practical.My suggestion is to not get sucked into this. If your design helps people use your product or understand what to do and only gets 5 likes, it’s still a great design.On a semi-related note, I’ve conducted a number of interviews lately and I’ve picked up on many things throughout the process of trying to hire a fellow designer. Every time a candidate interviews with us and answers questions in buzzword after buzzword, the general consensus is they can’t communicate their reasoning and thoughts very well for why they made certain design decisions.First off, shame on you if you scrolled down to this point without reading anything else. Secondly, here are the key takeaways you should remember from the article.If you enjoyed this article hit that heart ❤️ and share it with the world 👍Thanks for taking the time to read this article, if you have any comments about it I would love to hear what you think.You can also check out my other article I wrote.Thanks to Hayley Parke and Ali Torbati for helping me make my thoughts make more sense."
  },
  {
    "link": "https://m.signalvnoise.com/screenshot-ugh-youre-doing-it-wrong-d17121c60016?source=---------4-----------",
    "pic": "https://cdn-images-1.medium.com/fit/c/36/36/1*NttpgTIoHN2_KQttdrSNYw.png",
    "author": "",
    "date": "Mar 21",
    "photo": "https://cdn-images-1.medium.com/max/1000/1*d1FNE7DXAvgC4dNMO6dcZQ.png",
    "head": "Screenshot? Ugh, you’re doing it wrong!",
    "contents": "Your product’s success is based on a combination of factors, but the overall user experience tops them all. When it comes down to designing a new app or a site, sticking to best practices is a solid way to go, but during the creation of the big picture, it’s fairly easy to skimp over design elements that feel like nice to have but not necessary. However, the difference between good and bad experiences often comes down to how thoughtful we can design these small details.In this article, I’ll focus on visual feedback, microcopy and whitespace and you’ll see why these little big details are just as important as the more obvious elements of your design, and how they help determine the success of your product.Visual feedback might be easily overlooked in the greater design scheme, but it actually hold the entire experience together. When there’s no feedback there’s no proper interaction. Imagine talking to someone who doesn’t respond in any way — you can’t communicate at all. Same goes for your app.You must ensure that there is always some feedback for user actions, because it makes users feel in control. Visual feedbackIn real life, buttons, controls and objects respond to our interaction, and this is how people expect things to work. People expect a similar level of responsiveness from app elements.Visual feedback is also helpful when you need to inform users about results of an operation. You can use existing elements to deliver a feedback.Users want to know their current context in a system at any given time and apps shouldn’t keep them guessing — they should tell the user what’s happening via appropriate visual feedback. For frequent and minor actions, the response can be modest, while for infrequent and major actions, the response should be more substantial.Microcopy is the little bits of text that guide users through an experience. Microcopy examples are error messages, button labels, hint text. At a glance, these tiny clusters of words seem insignificant when compared to the overall app design. But surprisingly, they have a huge impact on conversions.A quick way to make your UI warmer and less mechanical is a human tone in the copy. If your product sounds human, it’s easier for people to trust you.How errors are communicated can have a huge impact on the way someone experiences your product. Often overlooked, an ill-constructed error message can fill users with frustration.A well-crafted error message, on the other hand, can turn a moment of frustration into a moment of delight. Thus, make error messages human, not technical, and suited to your audience.Microcopy is extremely contextual. That’s why it’s so valuable. It answers a very specific question people have and speaks to their concerns right on the spot. For example, microcopy can be fundamental in reassuring your users at the point of subscribing or sharing details. Whilst ‘not to spam/auto-tweet’ might be taken for granted by good marketers when asking for email address/access to the social network account connections, the user is less than sure. Thus, when people add their emails or connect their Twitter accounts, say “we hate spam as much as you do.”Whitespace (or negative space) is the areas of a design where there is no element placed by a designer. Elements of whitespace are space around images, margins, paddings, line-spacing and letter-spacing within text content. Although many may consider it a waste of valuable screen estate, whitespace is an essential element in user interface design.Clutter is bad. Cluttering your interface overloads your user with too much information: every added button, image, and line of text make the screen more complicated. If you don’t think any part of your design should be intentionally blank, take a look at example below and you’ll see what happens when too many objects competing for your attention.The power of white space comes from the limits of human attention and memory. Our short-term memory can hold a small amount of information (typically around 7 items or even less) in mind in an active, readily-available state for a short period of time (typically from 10 to 15 seconds, or sometimes up to a minute).If cluttering your interface overloads your user with too much information, then reducing the clutter will improve comprehension. Generous whitespace can make some of the messiest interfaces look inviting and simple. Whitespace reduces the amount of elements users see all at once and makes scanning much easier. The skill of using whitespace lies in providing your users with a digestible amount of content (chunks of content), then stripping away extraneous details.Whitespace creates the spaces around elements in the design to help them stand out or separate from the other elements. It helps communicate what’s most important and needs attention.Google Search homepage is a great example of using whitespace. The layout immediately facilitates the user goal by placing primary interaction element (search box) in front and center, with plenty of white space on either side to add emphasis.The law of proximity describes how the human eye perceives connections between visual elements. It states that objects near to each other appear similar. We can use whitespace to build perceived relationships between different elements. Take a look at this picture. Almost everyone sees two groups of dots, rather than simply 16 dots.Breaking the information up into appropriate groups can help make it feel more scannable and readable. In the form on the right, categorising the 15 fields into three groups makes the process feel easier. The amount of content is the same, but the impression on users is much different.Design with care. Each minor detail in your app’s UI deserves close attention because UX is the sum of all details working harmoniously:Thank you!Follow UX Planet: Twitter | FacebookOriginally published at babich.bizI’m a coder. I’m also blind. Blind as a bat, you might say. And I was born this way. When I mention this to my fellow human beings — the ones who’ve never suffered any form of visual impairment — they usually ask one of following questions:I get these questions again and again. So let me answer these three questions in this blog post. I’ll try and sketch out an image for those of you who are curious about accessibility, and how blind people use computers to code, and to do the work of the 21st century.I like this question, because it allows me to immediately explain how blind people actually use computers. A lot of people are under the impression that blind people require specially adapted computers in order to get anything done. Even some of my fellow Visually Impaired Persons (VIPs) tend to think this. Well let me debunk this myth right here and now. I am currently typing this on a normal Dell Inspiron 15r SE notebook, which can be bought in any laptop store that sells (somewhat less recent) laptops. The machine runs windows 8 (not my personal choice, but UEFI is too much of a pain to downgrade). All I did to adapt it was install an open-source screen reader called NVDA. A screen reader basically, at its most basic level — wait for it — reads the screen. It tells you the textual content of the screen with a synthesized text-to-speech Siri-like voice. Screen readers also allow for the use of a braille display, a device that consists of a line of refreshable braille cells that can form letters according to what content is highlighted on the screen.This is really all the adaptation a blind computer user needs. Using this program, I can do many things you probably wouldn’t imagine being able to do with your eyes closed, such as:The reason I’m naming all these mainstream technologies is to show you that I can use them just like people who aren’t ocularly challenged. If you’re writing the next big application, with a stunning UI and a great workflow, I humbly ask you to consider accessibility as part of the equation. In this day and age, there’s really no reason not to use the UI toolkits available. It’s a lot easier than you may think. Yes, these include the Android Activities, iOS NsViews and HTML5 widgets you may be thinking of. I joined Free Code Camp a few weeks back and really loved the concept. I’ve been pursuing a degree in Computer Science for the last few years, and had failed a semester that involved a lot of work with the MEAN stack. So I was really happy to find such an amazing community to be a part of and learn with. I’m sure I’ll pass my semester with flying colors this time. I sadly ran into accessibility issues when working through the by now famous Dash tutorials by General Assembly. The tutorials are undoubtedly good, but were completely unreadable for me because they chose to embed all their text in image slides that lack any textual description or content for screen readers to work with. Recall that screen readers read out textual content of the screen. They aren’t smart enough to interpret graphics. Fortunately, some fellow campers at the Free Code Camp were sympathetic towards my plight and volunteered to transcribe all these slides for me. This offer left me ‘flabbergasted’, as our dear western neighbors across the sea would say. I’m very grateful for the work these people have done to further my studying. You guys know who you are. Thanks a lot!If left paren x equals five right paren left brace print left paren quote hello world exclaim quote right paren right brace. This is how a typical if-block in a Java-ish programming language would be read to me. You can see that it’s rather verbose. I tend to turn off the notifications for parenthesis and brackets until I find I need to match brackets while debugging, so that I don’t go crazy from the rather wordy descriptions of these signs. Others have solved this problem by substituting the default ‘left brace’ for something like ‘lace’ or ‘begin’, just to save a few milliseconds. The rate of speech is extremely fast for people who aren’t used to it.For those of you who can’t follow this, it’s my computer reading out the first bit of this very blog post that I’m writing in NotePad++. So, how I code doesn’t actually differ all that much from how others code. I’ve learned how to touch type, and mentally conceptualize my code so that I can work with it just like you guys do. The only difference is that I barely ever use a mouse for anything. I tend to stick with hotkeys and the command line instead. Sadly though, in this field, all is not well. Premier tools that coders use every day, like the IntelliJ editor, as well as all its offshoots (PHPStorm, WebStorm, PyCharm), are completely inaccessible, due simply to the fact that the developers of these programs have not adhered to the accessibility guidelines. They’ve failed to give screen readers textual labels or accessibility descriptions to work with. The same goes for applications like SourceTree, which is slowly getting better, but is still a pain to use. I therefore have to keep looking for tutorials, programs and tools that are accessible, and cannot simply pick up any off-the-shelf IDE.I promised to answer all three questions, so I’ll keep that promise. Don’t expect anything too resounding, though. I dream just like you guys do. My mind translates experiences and impulses I’ve received during the day into dreams I have at night. The difference being that I don’t actually see anything. Instead, I hear, smell and feel everything, just like in real life. The reason for this is simple: dreams based on visual imagery pull from your already stored visual knowledge to construct that visual imagery. Since I’ve been blind since birth, I have no visual frame of reference. The visual portion of my dreams run into a big fat 404 error: image not found.A Free Code Camp volunteer asked me to write this blog post to share my way of doing things with the world. After the welcome I’ve received from this community, I was all too happy to write this. I really hope you guys have learned something from it. I could talk about this for hours, and this article has already grown far longer than I initially planned. If you have questions, come find me in the Free Code Camp chatrooms. I am Zersiax there, and I can be found by that name on Twitter as well.Thanks for reading this. I’ll see you later! (Sorry. I really couldn’t resist that one) :)I thought this would be fitting to repost — as my first-ever Medium post — the article that threw my life for a loop one year ago, back in January 2015.Y ou sit in your car, listening to a light rain ping quietly down on the hood. You’ve just finished your fourth trip of the night, and you sit back and relax. Not for long though, it’s a busy night and you accept another pickup request close by. As navigation begins, you check your mirrors, shift into drive, and pull out onto the road towards a new destination. You work your way across a few lanes of heavy traffic to make that first left coming up. After more lights and turns, you arrive at a busy pickup point and look for a safe space to pull over. Out of the crowd on the sidewalk, a person waves and heads your way.You’re about to find out where you’re going next.On the driver team at Uber, one of our jobs is to take the pressure off of drivers, so that they can focus on smooth and stress-free rides for everybody. We want to make sure that drivers have the best features possible directly in-app, and one of the most important features is a navigation system. So we started with a basic question:If you’re browsing for a new restaurant for lunch, or trying to find a lecture hall on a college campus, you’ll have different mapping needs than if you’re in the mountains on a two-day hike. And, if you’re commuting to work on a familiar daily route, or driving to a friend’s birthday party, your navigation needs are different from people driving with Uber. Why are one-size-fits-all digital maps not a good fit for Uber?It all boils down to this:For most drivers in most situations, your trip is a simple one: you’ve got a starting point, a destination, and the best route between the two. The end.If you’re driving with Uber, however, it’s all about that magic moment where a car and a passenger meet. Then you travel together to a new destination, and when your passenger leaves your car, you’re off to the next meeting point. If you are a driver on an uberPool trip, your route might have several overlapping pickups and dropoffs. Throw deliveries into the mix — where you might need to park and walk inside for a pickup — and navigation can get incredibly complicated.When it came to something as central as navigation, we knew how important it was to get things right. Uber is able to move fast with features, but for the navigation overhaul, our pace was much more deliberate.Committing to the long haul meant that we could dive deeply into the needs of drivers. We conducted driver interviews. We rode along with them to watch and listen to their pain points. We held in-office forums and gathered map and navigation related feedback. We shared prototypes, observed drivers interacting with them, and listened to their likes and dislikes. We set up an eye-tracking rig and analyzed how a driver’s eyes interact with the environment vs. a device screen. We built a car simulator in our office, which we connected to a gaming wheel controller, a video of typical driving scenarios, and a timed navigation prototype. We even built a physical map of Amsterdam out of paper.But we didn’t stop there. We sent our team across the US and all over the world with navigation prototypes and cameras to see what would happen when rubber met the road.It’s hard to overstate how valuable this first-person testing was. We understood that we needed a mapping + navigation tool that would be as useful over the canals of Amsterdam and through the tunnels of Boston as it would in the jammed streets of Jakarta or the one-way avenues of NYC. Day or night, uberX or uberPOOL, it needed to serve the unique needs of drivers.Unlike traditional navigation apps, Uber Navigation has to help its users answer the question “What’s next?”. Once a driver successfully completes one trip, it’s important that navigation is ready with the best route for the next trip.Uber Navigation also needs to differentiate between types of locations and activities, so we designed distinct visuals for the variety of actions a driver might take on different legs of a trip. Custom cartography, maneuver iconography, pins, side-of-street-indicators, route line previews, and camera animations all work together to explain the journey.Take the “3-Foot-1-Second” Rule: drivers are looking at a smartphone-sized screen from about three feet away, for about one second at a time. This means that “glanceability” and “tappability” are priorities. Designing the new navigation experience was all about answering the question “what is the essential information that the user needs right now?” Everything else had to take a backseat.For gestures, we wanted drivers to have freedom, but also minimal need to interact while driving. We do enable a driver to pan and zoom if they choose, but we also made sure to build in an effortless single tap gesture to toggle between an overview state and a first person navigation, or to inspect the destination point.One of our essential new navigation features is Night Mode. Many people drive with Uber at night, and sometimes for hours at a time. The default day settings can cause eye-strain as a driver readjusts from the bright screen to the dark streets outside. Night Mode protects drivers from light pollution that would otherwise be a real ergonomic and safety hazard.For Night Mode, we wanted a subdued color palette. Designers sat in a windowless, dark room and analyzed multiple color schemes. We were amazed by how different they looked in an unlit room compared to a normal bright conference room. We took our favorite options out on night-time drive tests, and from there we pushed and pulled values until the guidance UI, map UI, and map styles all felt harmonious.Uber Navigation is custom tailored for drivers, and we’re not done yet. Every day we’re collecting great constructive feedback from drivers, and we’ll be prioritizing their feedback in upcoming versions. Plus, now that we’ve rolled out our starting lineup, we’re excited for all of the design possibilities to come.We are so proud of everyone who made this happen. And while this post is design-focused, we want to recognize over a year of hard work by designers, engineers, researchers, and product managers. Most of all, we’d like to thank the drivers for their invaluable feedback. Thank you!Are you a map design enthusiast, routing wonk, driver? Have any thoughts about the new navigation? Let us know what you think in the comments below!ByEvelyn KimCady WachsmanChristine TaoBo Paweena AttayadmawittayaMap data source © TomTomThroughout life, you hear the cheesy saying, “quality over quantity.” In most situations this is good advice. Not in the design world.To be clear, this isn’t an excuse to show 10 half-assed designs. This means, instead of showing one design you believe to be perfect, show 3 great ideas. The ampersand in the title of this section is important — we’re trying to strike a balance and deliver on both.Time for a real-world example: Most projects start with a list of product requirements. The people who come up with the requirements usually have an idea of how they believe the product should look (whether they tell you or not). Quantity and quality comes into play when there are differing opinions about implementation. The best way to keep the project moving is to show at least two examples:Even if you know option 1 won’t work in your head, showing the initial design is critical. Stakeholders won’t be satisfied until they can actually see its shortcomings. Usually a mashup of the two concepts will be the final outcome, but that’s better than executing a design you disagree with.You could have the world’s best design, but if you don’t know how to explain the problem being addressed and the reason for your design decisions, the design will never get approved. Context is king when it comes to pitching your idea or concept to others.There are two easy steps that will help you give a great presentation:If all you do is show your final design without providing context, people may not understand how you arrived at your conclusion and ask you to explore various other approaches. At that point, defending your work and pointing out the flaws in their suggestions might sound more defensive than you would like.This is something that is very important to me and a major part of being in a creative profession. I always make it a priority to learn new skills (software, leadership, dev languages, etc.) — whatever I need to continue to grow as a designer.I don’t buy the excuse that people are too busy to learn, because almost everyone has some free time at some point in the day. It comes down to what you do in that free time.At my first job I learned how to write html, css and some basic js and became a “developer.” When I took my second job I learned how to make illustrations and add animations to my designs. At my current job, I’m learning how to communicate my thoughts more clearly and build prototypes to better demonstrate my designs.I never want to get to a point in my career or life, when I have the feeling that there is no more room for growth or learning. That’s why I am constantly striving to develop new skills whenever I can.Trendy words/designs/clothes, etc. are exactly that: trends. They will, without a doubt, die out and look dated (Remember skeumorphic design). I try to avoid incorporating short-lived trends whenever I can in life and in my career.Sometimes, you can get caught up trying to get more likes or favorites or whatever it may be, by following trends. I see tons of concepts with text or buttons overflowing past the background a random distance. Or I see a title that fits perfectly with the image designers chose but if any other image was used, the same layout would never work. Yet these shots have hundreds of likes…Disclaimer: I understand dribbble and other sites like it are meant to somewhat of a creative release for people. Therefore some of the work is strictly for fun and was never meant to be used in the real world. I’m not saying trying new things and exploring new styles is bad — but it’s not practical.My suggestion is to not get sucked into this. If your design helps people use your product or understand what to do and only gets 5 likes, it’s still a great design.On a semi-related note, I’ve conducted a number of interviews lately and I’ve picked up on many things throughout the process of trying to hire a fellow designer. Every time a candidate interviews with us and answers questions in buzzword after buzzword, the general consensus is they can’t communicate their reasoning and thoughts very well for why they made certain design decisions.First off, shame on you if you scrolled down to this point without reading anything else. Secondly, here are the key takeaways you should remember from the article.If you enjoyed this article hit that heart ❤️ and share it with the world 👍Thanks for taking the time to read this article, if you have any comments about it I would love to hear what you think.You can also check out my other article I wrote.Thanks to Hayley Parke and Ali Torbati for helping me make my thoughts make more sense.A proper sharing feature has been part of iOS for years. It has a consistent, system-level UI that’s available from most any app with anything worth sharing and yet no one seems to use it. Well, no one but us geeks, right? Everyone else just takes screenshots—which require mastering an unintuitive multi-button press and a fair amount of dexterity.I moaned when people started posting screenshots of highlighted selections from articles to beat the 140 character limit on Twitter because they just shared a picture of text that I can’t copy, reformat, enlarge, etc. I’ve been that guy when friends send a screenshot of a product rather than a link. Sharing properly is a very type-A process that I dutifully complete out of ease for my friends and respect for the content!That’s why my inner pedant was delighted when Instagram noticed I had taken a screenshot and gently nudged me to use the proper share features.It’s a really nice solution that gently guides the user to the correct way to share. I’ll admit this is probably the solution I’d have designed, too. The built-in Share feature should be easier and yet friends and relatives who can barely download an app find screenshotting to be second nature.That’s why I was delighted to see Amazon’s take on the same problem. Where Instagram’s design is a gentle scolding, Ahem! I see you have no idea what you’re doing, Amazon’s much scrappier version says, Oh you made a screenshot? Cool, lemme help you with that.Amazon shows a similar, though more obvious, banner after you make a screenshot but it does things a little differently after that. For one, it uses the system’s Share Sheet which is familiar and provides a lot more options than Instagram’s custom one.More important than that, however, is the payload. Amazon shares my screenshot and then adds a URL to it. It’s a subtle difference but Amazon’s version makes me feel better. Where Instagram gets my intent and tries to help me do the right thing, it replaced my content. Amazon’s design let’s me do what I intended but helps me do it better. In the screenshots above a major difference is posting to Twitter. Instagram’s post wouldn’t include an image, Amazon’s would.As a designer I love being surprised by solutions I wouldn’t have come up with. I can absolutely see how Instagram arrived at their solution. Part of UI design is guiding users back when they go off track. Designers want to change the world by making things easier, more understandable, more enjoyable—more ideal. That completely resonates but I can’t help but admire the audacity of Amazon’s designers who have accepted the world as it is and humbly offered a helping hand. Kudos!"
  }
]